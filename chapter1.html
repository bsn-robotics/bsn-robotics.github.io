<!DOCTYPE html>
<html>
  <head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <link rel="stylesheet" href="style.css" type="text/css">
    <title>SLAM</title>
  </head>
  <body><page size="A4">
      <h2>Аналитический обзор существующих алгоритмов навигации и их
        практических реализаций</h2>
      <h3>1.1 Общие сведения об алгоритмах навигации в неизвестной среде</h3>
      <p><page size="A4"></page></p>
      <!--Диссертация 2 конец-->
      <p>В настоящее время для навигации робота в условиях недетерминированной
        среды, применяются различные алгоритмы картографирования среды,
        определения своего положения в пространстве относительно составленной
        карты, а также решения задачи поиска возможной траектории движения.
        Метод SLAM (Simultaneous Localization and Mapping) <a href="source.html#1_3">[3]</a>,
        позволяет одновременно решать две задачи – картографирования неизвестной
        среды и локализации робота<a href="source.html#1_3"></a>.<!--Ссылка на метод-->На
        данный момент существует множество различных алгоритмов SLAM,
        отличающихся как по типу входной информации, представлению окружающего
        пространства в виде карты, так и по методам обработки этой информации.</p>
      <p>Классификация алгоритмов локализации по размерности<br>
        картографируемого пространства:</p>
      <p>- двумерная локализация на плоскости (2D-SLAM);</p>
      <p>- трехмерная локализация в пространстве (3D-SLAM);</p>
      <p>- визуальная локализация по R, G, B (Red, Green, Blue) компонентам
        изображения с видеокамеры (Visual-SLAM или Colour-SLAM);</p>
      <p>- визуальная трехмерная локализация в пространстве, с использованием
        времепролетной камеры (RGB-D SLAM).</p>
      <p>При использовании наиболее простых лазерных дальномеров входной
        информацией для алгоритма является двумерное горизонтальное сечение
        рельефа окружающих объектов, соответственно для обработки применяется
        2D-SLAM. При наличии дополнительной оси сканирования можно получить
        трехмерное облако точек, дающее представление объектов помещения с
        учетом их взаимного расположения в пространстве, поэтому здесь применим
        3D-SLAM. Однако в наше время набирают популярность датчики, позволяющие
        получить трехмерное цветное изображение объектов, к примеру,
        времепролетные камеры, Kinect и им подобные; для обработки таких
        изображений с целью локализации и построения карты применяются алгоритмы
        RGB-D SLAM. Следует отметить, что подавляющее большинство алгоритмов
        локализации на плоскости могут быть расширены на трехмерное
        пространство.</p>
      <p>Необходимо рассмотреть базовые принципы алгоритмов SLAM. В качестве
        точки отсчета алгоритмы SLAM используют начальное положение робота,
        относительно которого строятся карта и траектория движения.<br>
        Задача SLAM разделяется на несколько подзадач (см. рисунок 1) <a href="source.html#3">[3]</a>:</p>
      <p>а) вычисление текущего положения робота на основе данных с
        одометрических датчиков и камеры;</p>
      <p>б) нахождение новых ключевых точек, т. е. предположительного
        препятствия в пространстве;</p>
      <p>в) ассоциация новых и старых данных (англ. Data association) — если
        новую ключевую точку можно сопоставить со старой, то вес старой ключевой
        точки увеличивается. В противном случае, новая ключевая точка
        добавляется в карту местности;</p>
      <p>г) хранение карты местности в памяти.</p>
      <p>В перечислении <b>б</b><!--Можно ли так писать ?--> такими точками
        могут служить легко распознаваемые ориентиры, часто встречающиеся в
        пространстве, — углы стен, прямые линии, контрастные точки (для
        видеокамеры). И здесь очень важна однозначная идентификация ключевой
        точки. Робот, встречая ориентир, который он уже видел, должен точно его
        распознать. Для однозначного распознавания одной ключевой точки от
        другой существуют различные дескрипторы. Дескриптор выполняет поиск
        ключевых точек&nbsp; и запоминает их отличительные признаки. Иными
        словами, об одной и той же ключевой точке могут быть получены данные из
        разных положений робота в пространстве. При этом новые ключевые точки
        будут временными, пока не будет проведена ассоциация.</p>
      <p>Эти подзадачи могут быть реализованы разными способами, комбинации
        которых дают различные варианты исполнения алгоритмов.</p>
      <br>
      <p><img style="width: 528px; height: 332px;" title="01" alt="01" src="img/chapter1_01.png"><br>
        Рисунок 1 – Схема SLAM-алгоритма</p>
      <p>Поскольку в задании на выпускную работу в качестве датчика была дана
        времепролетная камера Microsoft Kinect 2.0, которая является RGB-D
        сенсором, то далее будут рассмотрены алгоритмы RGB-D SLAM.</p>
      <h3>1.2 Реализации RGB-D SLAM алгоритмов</h3>
      <h4> 1.2.1 RTAB-Map</h4>
      <p> RTAB-Map (Real-Time Appearance-Based Mapping) – алгоритм SLAM на
        основе графа для RGB-D камер. Использует визуальный детектор замыкания
        петель для оценки, откуда получен новый ключевой кадр – из прежнего или
        нового положения (cм. рисунок 2). Для ассоциации новых и старых данных
        алгоритм сопоставляет кадры, полученные с разных ракурсов.</p>
      <p><img style="width: 495px; height: 274px;" title="02" alt="02" src="img/chapter1_02.png"></p>
      <p>Рисунок 2 - Cхема работы RTAB-Map</p>
      <p>Сопоставление кадров, в зависимости от предварительных установок, может
        достигаться за счет использования различных детекторов и дескрипторов
        ключевых точек: FAST, SIFT, SURF, BRIEF,&nbsp; BRISK, ORB <a href="source.html#4">[4]</a>.</p>
      <p>- Детектор FAST (Features from Accelerated Test) <a href="source.html#5">[5]</a><br>
        Cуществуют детекторы определяющие ключевые точки на изображении, в
        частности, углы, применяя некоторую модель или алгоритм напрямую к
        пикселям исходного изображения.&nbsp;Альтернативный подход состоит в
        том, чтобы использовать алгоритмы машинного обучения для тренировки
        классификатора точек на некотором множестве изображений. FAST-детектор
        строит деревья решений для классификации пикселей. Для каждого пикселя <b>p</b>
        изображения рассматривается окружность с центром в этой точке, которая
        вписана в квадрат со стороной 7 пикселей (см. рисунок 3). Окружность
        проходит через 16 пикселей окрестности.</p>
      <p><img style="width: 201px; height: 197px;" longdesc="01" title="01" alt="01"
          src="SLAM/chapter1_01.jpg"></p>
      <p>Рисунок 3 – Рабочая окрестность пикселя при использовании FAST
        детектора</p>
      <p>- Дескриптор SIFT (Scale Invariant Feature Transform) <a href="source.html#5">[5]</a><br>
        Для формирования дескриптора SIFT сначала вычисляются значения магнитуды
        и ориентации градиента в каждом пикселе, принадлежащем окрестности
        ключевой точки размером 16x16 пикселей. Магнитуды градиентов при этом
        учитываются с весами, пропорциональными значению функции плотности
        нормального распределения с математическим ожиданием в рассматриваемой
        ключевой точке и стандартным отклонением, равным половине ширины
        окрестности<br>
        (веса Гауссова распределения используются для того, чтобы уменьшить<br>
        влияние на итоговый дескриптор градиентов, вычисленных в пикселях,<br>
        находящихся дальше от ключевой точки).</p>
      <p> - Дескриптор SURF (Speeded up Robust Features) <a href="source.html#5">[5]</a>
        <br>
        Относится к числу тех дескрипторов, которые одновременно выполняют поиск
        ключевых точек и строят их описание, инвариантное к изменению масштаба и
        вращения. Кроме того, сам поиск ключевых точек обладает инвариантностью
        в том смысле, что повернутый объект сцены имеет тот же набор ключевых
        точек, что и образец.</p>
      <p> - Дескриптор BRIEF (Binary Robust Independent Elementary Features) <a
          href="source.html#5">[5]</a><br>
        Цель создания BRIEF-дескриптора состояла в том, чтобы обеспечить
        распознавание одинаковых участков изображения, которые были сняты с
        разных точек зрения. При этом ставилась задача максимально уменьшить
        количество выполняемых вычислений.</p>
      <p>- BRISK (Binary Robust Invariant Scalable Key-points) <a href="source.html#6">[6]</a><br>
        Данный метод представлен в 2011г. Детектирование ключевых точек
        осуществляется с помощью FAST, в качестве дескриптора используется
        BRIEF, но в их работу были внесены некоторые изменения. BRISK отличается
        от остальных методов тем, что он определяет наибольшее количество
        ключевых точек, но, к сожалению, в них попадает и цифровой шум, при этом
        на фильтрацию образовавшихся ложных связей затрачивается значительное
        количество времени, хотя итоговая точность высока.</p>
      <p> - ORB (Oriented FAST and Rotated Brief) <a href="source.html#6">[6]</a><br>
        Представлен также в 2011г. В его основе лежит комбинация таких
        алгоритмов как детектор FAST и дескриптор BRIEF с некоторыми
        улучшениями. Метод ORB имеет лучшую скорость в вычислении ключевых точек
        и расчета их дескрипторов, что позволяет использовать его в задачах, где
        необходима обработка изображений в реальном времени. Одной из таких
        задач является слежение за движущимся объектом. Но высокая скорость
        работы сказывается на точности сопоставления изображений не в лучшую
        сторону. Наличие цифрового шума или размытие изображений еще больше
        ухудшает результаты программы.</p>
      <p>Следует подробнее рассмотреть работу RTAB-Map.</p>
      <p>Каждый узел графа (ключевой кадр) содержит свою позицию в 3D
        пространстве,&nbsp; цветную 3D карту глубины и список ключевых точек
        карты, которые обнаружены на данном изображении. Рёбра графа отражают
        связь между этими узлами. Связь создаётся только между соседними узлами
        или узлами, между которыми детектируется замыкание петли <a href="source.html#7">[7]</a>.
      </p>
      <p>Детектор замыкания петель осуществляет поиск соотношения между
        дескрипторами ключевых точек текущего ключевого кадра и дескрипторами
        ключевых точек, обнаруженных ранее (см. рисунок 4). Если количество
        общих ключевых точек у текущего ключевого кадра и у кадра с наибольшим
        соответствием превышает определённый порог, то происходит замыкание
        петли. При этом позиция текущего кадра уточняется для совпадения
        ключевых кадров с предыдущим, а остальные узлы петли оптимизируются. И
        добавляется соответствующее новое ребро <a href="source.html#7">[7]</a>.
      </p>
      <p> После нахождения замыкания петли позиции графа оптимизируются с целью
        минимизации ошибки в графе.</p>
      <p><img style="width: 250px; height: 299px;" longdesc="02" title="02" alt="02"
          src="SLAM/chapter1_02_loop.jpg"></p>
      <p><br>
      </p>
      <p>Рисунок 4 - Работа детектора замыкания петель</p>
      <p>Алгоритм работы:</p>
      <p>- первый кадр становится ключевым. Его карта глубины добавляется на 3D
        кадр. А дескрипторы ключевых точек в “мешок слов” (англ. bag of words).
        Bag of words – это метод классификации изображений, использует в
        качестве описания гистограмму вхождений отдельных шаблонов в
        изображение;</p>
      <p>- следующий ключевой кадр будет добавлен, только если робот
        переместится на некоторое расстояние или прошёл заданный промежуток
        времени;</p>
      <p>- положение нового ключевого кадра уточняется благодаря соотношению
        ключевых точек двух кадров и расстоянию, имеющемуся благодаря карте
        глубины;</p>
      <p>- выполняется проверка обнаружения замыкания петли;</p>
      <p>- 3D карта нового ключевого кадра добавляется на карту. А дескрипторы
        ключевых кадров в bag of words. И процесс начинается сначала.</p>
      <p> Точность построения карты определяется размером ячейки сетки графа и
        составляет 0,05 м <a href="source.html#7">[7]</a>.<br>
        Трехмерная карта, полученная с помощью RTAB-Map, представлена на рисунке
        5. </p>
      <p><img style="width: 448px; height: 407px;" title="1_03" alt="1_03" src="img/chapter1_03.png"></p>
      <p>Рисунок 5 – Трехмерная карта, полученная с помощью RTAB-Map<br>
      </p>
      <h4> 1.2.2 ElasticFusion</h4>
      <p> ElasticFusion позволяет строить трехмерную карту окружения.<br>
        Алгоритм не использует граф посещённых локаций и полностью опирается
        только на построенную карту при локализации и поиске замыканий петель.
        Для поиска замыканий алгоритм случайно выбирает небольшие части карты, с
        которыми впоследствии сравниваются новые кадры. После нахождения
        замыкания участок карты деформируется в соответствии с накопленной
        ошибкой позиционирования.<br>
        Точность построения карты составляет 0,03 м <a href="source.html#8">[8]</a>.</p>
      <p>Трехмерная карта, полученная с помощью ElasticFusion, представлена на
        рисунке 6.<br>
      </p>
      <p><img style="width: 473px; height: 485px;" title="1_04" alt="1_04" src="img/chapter1_04.png"></p>
      <p>Рисунок 6 – Трехмерная карта, полученная с помощью ElasticFusion<br>
      </p>
      <h4> 1.2.3 RGBDSLAM в составе ROS </h4>
      <p> RGBDSLAM – это решение для RGB-D камер, которое позволяет получать
        трехмерную карту окружения в виде цветного облака точек (см. рисунок 7)
        <a href="source.html#9">[9]</a>. Это достигается за счет использования
        визуальных дескрипторов ключевых точек SURF или SIFT для совмещения пар
        полученных изображений. Кроме того используется метод RANSAC для
        надежной оценки трехмерного преобразования между ними.</p>
      <p>RANSAC&nbsp;(RANdom SAmple Consensus)&nbsp;— стабильный метод оценки
        параметров модели на основе&nbsp;случайных выборок. Схема RANSAC
        устойчива к зашумлённости исходных данных. Метод был предложен в 1981
        году Фишлером и Боллесом. Схема работы метода RANSAC заключается в
        циклическом повторении поиска матрицы трансформации между случайно
        выбираемыми четырьмя ключевыми точками на одном изображении и
        соответствующим им четырём точкам на втором <a href="source.html#10">[10]</a>.</p>
      <p>Возможность выбора между двумя вариантами дескрипторов, позволяет
        работать алгоритму в различных условиях освещения.<br>
        Чтобы выполнить обработку, текущее изображение сопоставляется с
        предыдущим. Впоследствии создается граф, узлы которого соответствуют
        кадрам с камеры, а ребра которого соответствуют оцененным трехмерным
        преобразованиям. Затем граф оптимизируется для уменьшения накопленных
        ошибок позиционирования.</p>
      <p>Точность построения карты 0,05 м <a href="source.html#8">[8]</a>.</p>
      <p><img style="width: 498px; height: 360px;" title="1_05" alt="1_05" src="img/chapter1_05.jpg"><br>
      </p>
      <p>Рисунок 7 –&nbsp; Трехмерная карта, полученная с помощью RGBDSLAM<br>
      </p>
      <h4> 1.2.4 ORB-SLAM</h4>
      <p> ORB-SLAM (Oriented FAST and Rotated BRIEF SLAM) – визуальный
        монокулярный алгоритм SLAM <a href="source.html#11">[11]</a>.
        Существует модернизация данного алгоритма для применения с RGB-D
        камерами и стереопарами.<br>
        Алгоритм использует детектор и дескриптор ключевых точек ORB, и bag of
        words оптимизацию. Метод основан на отслеживании ключевых точек, в
        результате чего, в качестве ключевого кадра выступает изображение с
        набором ключевых точек и найденных на обоих кадрах. Получаемые
        ORB-дескрипторы ключевых точек инвариантны к углу зрения, повороту
        камеры и освещенности. Это позволяет алгоритму с высокой точностью и
        надежностью отслеживать замыкания петель, а также обеспечивает высокую
        надежность при релокализации.<br>
        По сравнению с другими дескрипторами ORB вычисляется за меньшее время.</p>
      <p>Точность построения карты 0,05 м.</p>
      <p>Трехмерная карта, полученная с помощью ORB-SLAM, представлена на
        рисунке 8.</p>
      <p><img style="width: 466px; height: 315px;" title="1_06" alt="1_06" src="img/chapter1_06.png"></p>
      <p>Рисунок 8 – Трехмерная карта, полученная с помощью ORB-SLAM<br>
      </p>
      <h3> 1.3 Сравнение реализаций SLAM алгоритмов</h3>
      <p> Важным критерием сравнения является совместимость с датчиками. В
        задании на выпускную работу в качестве датчика была дана времепролетная
        камера Microsoft Kinect 2.0.<br>
        Таблица 1 – Сравнительная характеристика реализаций SLAM-алгоритмов</p>
      <p> Реализация<br>
        RTAB-Map<br>
        ElasticFusion<br>
        <br>
        RGBDSLAM<br>
        ORB-SLAM<br>
        <br>
        Использованные методы<br>
        RANSAC,<br>
        bag of words<br>
        Surfels<br>
        RANSAC<br>
        bag of words<br>
        Детекторы<br>
        SURF,&nbsp; FAST, ORB<br>
        н/д<br>
        SURF, SIFT<br>
        ORB<br>
        Дескрипторы<br>
        SURF, SIFT, BRIEF, ORB<br>
        н/д<br>
        SURF<br>
        ORB<br>
        Точность составления карты , м<br>
        0,05<br>
        0,03<br>
        0,05<br>
        0,05<br>
        Адаптирована для использования с RGB-D сенсором Kinect 2.0.<br>
        Да<br>
        Нет<br>
        Нет<br>
        Нет<br>
        Интеграция с ROS<br>
        Да<br>
        Нет<br>
        Да<br>
        Нет<br>
      </p>
      <p>Из таблицы 1 можно сделать сравнительный вывод в пользу реализации
        RTAB-MAP. Несмотря на то, что он менее точно выполняет локализацию по
        сравнению с ElasticFusion, он обладает рядом преимуществ: <br>
        - позволяет использовать разные детекторы и дескрипторы в зависимости от
        задачи;<br>
        – он единственный адаптирован для использования с Kinect 2.0.</p>
      <h3> 1.3 Выводы по разделу</h3>
      <p> В данном разделе были рассмотрены наиболее известные и представляющие
        интерес реализации метода одновременной локализации и построения карты.<!-- метода именно 3D !!!-->
        Аналитический обзор показал, что большинство существующих реализаций не
        адаптировано для использования с времепролетной камерой Microsoft Kinect
        2.0.</p>
      <p>В рамках обзора проведен анализ реализаций, учитывающий достоинства и
        недостатки каждого алгоритма. Результат анализа сведён в таблицу 1, на
        основании которой был произведен выбор в пользу реализации RTAB-Map для
        дальнейшего использования в качестве основы для решения задачи
        навигации.</p>
      <p><!-- Реализация RTAB-Map не решает полностью задачу навигации, она не способна найти траекторию движения робота к заданной точке, но позволяет, используя метод SLAM построить карту неизвестной среды.-->
        Метод SLAM позволяет составить карту неизвестной среды. Но для решения
        задачи навигации дополнительно требуется выполнение следующих подзадач:
        автоматическое планирование маршрута, управление перемещениями робота и
        обход препятствий, коррекция траектории движения робота. Для этого
        требуется разработка собственного программного обеспечения.</p>
      <p>Целью настоящей работы является разработка и практическая реализация
        алгоритмов навигации робота в неизвестной среде, которые полностью
        решают задачу навигации, используя при этом возможности времепролетной
        камеры Microsoft Kinect 2.0.</p>
      <p><br>
      </p>
    </page>
  </body>
</html>
